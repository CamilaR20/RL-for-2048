import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F

class ConvBlock(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(ConvBlock, self).__init__()
        d = output_dim // 4
        self.conv1 = nn.Conv2d(input_dim, d, 1, padding='same')
        self.conv2 = nn.Conv2d(input_dim, d, 2, padding='same')
        self.conv3 = nn.Conv2d(input_dim, d, 3, padding='same')
        self.conv4 = nn.Conv2d(input_dim, d, 4, padding='same')

    def forward(self, x):
        output1 = self.conv1(x)
        output2 = self.conv2(x)
        output3 = self.conv3(x)
        output4 = self.conv4(x)
        return torch.cat((output1, output2, output3, output4), dim=1)

class DQN(nn.Module):
    def __init__(self):
        super(DQN, self).__init__()
        self.conv1 = ConvBlock(16, 2048)
        self.conv2 = ConvBlock(2048, 2048)
        self.conv3 = ConvBlock(2048, 2048)
        self.dense1 = nn.Linear(2048 * 16, 1024)
        self.dense6 = nn.Linear(1024, 4)
    
    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.relu(self.conv2(x))
        x = F.relu(self.conv3(x))
        x = nn.Flatten()(x)
        x = F.dropout(self.dense1(x))
        return self.dense6(x)


if __name__ == "__main__":
#     score_list = [2952, 1352, 1960, 900, 1044, 1428, 1432, 1352, 612, 2404, 2280, 1828, 2152, 1520, 2452, 652, 1100, 1428, 188, 1528, 1336, 600, 1984, 964, 520, 2716, 2056, 1540, 3344, 1412, 2832, 1124, 3052, 3340, 2704, 2856, 3024, 3224, 5272, 3400, 3044, 1268, 5064, 3184, 2908, 3420, 3064, 3212, 2348, 3156, 3152, 6952, 4700, 3284, 2312, 4932, 5684, 3100, 2288, 7176, 5424, 4912, 2820, 2780, 7052, 3204, 3344, 6120, 6760, 7276, 6240, 7028, 7212, 7636, 3352, 7136, 3252, 6064, 7488, 5304, 3744, 5000, 7456, 15916, 3200, 16880, 7452, 12084, 5756, 11020, 5300, 5776, 1756, 7224, 11540, 8896, 2520, 7168, 7272, 3472, 5304, 4736, 13824, 9472, 7336, 6888, 15368, 8944, 6644, 6856, 2452, 12788, 15880, 16188, 7360, 7380, 10764, 5408, 2332, 4800, 12168, 12340, 7184, 21652, 3100, 12060, 7468, 15524, 8180, 12104, 16224, 13476, 4092, 3344, 16180, 7360, 1732, 10432, 11980, 12488, 652, 5336, 5220, 13604, 12416, 6956, 16220, 4952, 7096, 560, 15408, 16420, 16512, 812, 12400, 6956, 3160, 5328, 7052, 15380, 7252, 6848, 6748, 15612, 9608, 1180, 2656, 15704, 16352, 13556, 13988, 22716, 11764, 6184, 6668, 2320, 15848, 12224, 12340, 4036, 652, 12004, 10608, 22440, 17308, 6424, 10504, 11476, 3008, 7116, 4564, 15388, 7692, 22732, 4888, 24052, 6628, 2908, 2644, 6116, 12060, 7212, 2736, 13828, 15948, 5736, 9868, 12428, 7092, 7984, 31332, 4328, 7040, 10572, 4540, 7208, 11500, 9916, 20716, 6212, 8080, 13664, 11800, 3504, 14344, 7348, 25380, 12352, 3520, 13492, 26428, 6132, 7036, 12652, 7060, 15792, 7028, 10584, 16044, 14452, 6336, 9464, 4908, 14244, 12180, 4372, 7064, 10400, 7640, 3372, 10436, 15628, 6420, 6896, 10492, 7800, 24176, 6640, 16204, 29408, 16804, 16436, 7136, 8012, 7760, 3484, 5348, 30844, 6796, 14132, 14072, 2768, 7356, 10328, 16004, 4700, 17196, 12128, 12604, 5308, 26960, 10464, 15084, 5116, 18324, 11592, 15468, 6480, 17152, 6988, 14148, 6384, 13840, 5924, 3536, 10452, 12436, 7220, 7012, 5596, 12008, 6876, 3296, 6356, 7056, 5856, 14324, 2668, 11624, 7660, 14040, 7356, 5472, 4072, 8372, 15608, 14976, 16704, 14864, 15460, 15536, 14040, 1340, 10296, 26224, 12416, 8932, 21608, 18020, 16120, 10284, 12424, 7192, 7100, 3172, 11524, 12456, 7004, 7640, 11036, 7196, 12444, 15688, 4660, 7428, 6760, 1192, 8940, 16016, 15976, 8624, 5072, 24812, 13240, 3192, 10136, 7000, 8760, 15344, 2556, 7328, 23080, 7012, 6596, 15788, 8052, 14132, 19512, 12456, 15732, 13932, 3684, 11776, 3824, 5476, 16244, 3028, 15064, 16044, 7456, 12616, 16072, 3180, 5696, 13664, 16116, 16544, 5480, 5408, 16860, 13060, 7184, 18800, 11168, 12076, 14412, 14376, 5320, 12168, 14324, 7756, 12216, 1552, 14216, 12072, 16020, 15420, 2880, 10476, 8684, 16208, 6884, 12404, 7156, 23476, 16168, 6840, 10416, 16816, 12384, 16192, 12392, 12128, 13184, 3160, 7436, 7072, 14068, 6100, 14160, 7204, 6356, 14440, 15948, 15688, 11440, 3792, 12400, 7776, 6196, 15760, 6844, 3184, 15364, 6012, 30452, 6408, 12412, 17356, 2396, 8824, 2592, 7364, 7364, 14644, 16256, 5992, 14324, 10228, 12140, 7088, 7860, 3020, 3100, 1380, 5320, 11472, 11328, 6484, 1452, 10060, 14384, 5552, 11776, 16316, 632, 3292, 7476, 10792, 13288, 16480, 6852, 10644, 10388, 7412, 11864, 580, 5772, 14444, 16164, 1472, 14752, 6380, 6404, 412, 14280, 14728, 7384, 5408, 10932, 5320, 4760, 14372, 16068, 12504, 11380, 3160, 13776, 16060, 2904, 2008, 12572, 16292, 12164, 13896, 15968, 11228, 4812, 12088, 2288, 17516, 18636, 12128, 7188, 23304, 17260, 5724, 6644, 10956, 7236, 11024, 5692, 29648, 11712, 25116, 8000, 15932, 10832, 11916, 6124, 7360, 16276, 3988, 14816, 10960, 16012, 16152, 12504, 8608, 13596, 3376, 15392, 12588, 14436, 7356, 7036, 1584, 12196, 7336, 15348, 7852, 14112, 5540, 14464, 14312, 8244, 6760, 14524, 14204, 9796, 22536, 16088, 15788, 7708, 5744, 16796, 3028, 11980, 8136, 7432, 14128, 7284, 14616, 6804, 7500, 7068, 8072, 15784, 7424, 5308, 2152, 7324, 7036, 14652, 3356, 13548, 12484, 27656, 6228, 4896, 14256, 13420, 15400, 7444, 12380, 14372, 7064, 3060, 1636, 12068, 11444, 8724, 13300, 4544, 7696, 25368, 9040, 3816, 8876, 11752, 27168, 13560, 21628, 11912, 14652, 7416, 11856, 6400, 14736, 6408, 16604, 16148, 31004, 12268, 16000, 12260, 4880, 21296, 5716, 15728, 2968, 15972, 16288, 7552, 16124, 5652, 7796, 1432, 3436, 6892, 5308, 12124, 16060, 23068, 5472, 3864, 15712, 6848, 3760, 7160, 12596, 7044, 5356, 25152, 5740, 1420, 12392, 9680, 2496, 26432, 16500, 10404, 15656, 7924, 2308, 15152, 16244, 26128, 22996, 616, 13832, 10456, 8052, 7492, 15516, 15748, 4636, 3212, 7468, 3168, 5980, 12376, 14208, 7440, 2984, 19512, 15468, 12240, 11832, 7256, 11432, 14384, 11968, 11356, 7196, 17036, 12204, 3104, 16372, 15628, 15084, 26392, 16192, 14612, 7356, 8744, 13568, 3044, 10664, 3128, 17728, 7492, 12276, 3020, 6520, 21476, 7360, 16460, 16204, 27284, 14596, 612, 7120, 9088, 15312, 11660, 15276, 13188, 14468, 3500, 7508, 10332, 2368, 12172, 4972, 4928, 2848, 14348, 15892, 15132, 12888, 1420, 1348, 2788, 9316, 26560, 7224, 12024, 14432, 9572, 15604, 10416, 16740, 14448, 12184, 4700, 12504, 10264, 7372, 4996, 9828, 9276, 10388, 11476, 6048, 13340, 16316, 11380, 14616, 13040, 1412, 15888, 16024, 14372, 15028, 15668, 20240, 15460, 6964, 4052, 15284, 8756, 2628, 15792, 15992, 716, 7204, 36236, 17372, 796, 4804, 14768, 3368, 32060, 12352, 1160, 14380, 12168, 15280, 13408, 10292, 1644, 9900, 15032, 7224, 15744, 10224, 6000, 8080, 12036, 12060, 15872, 7148, 12224, 15860, 5536, 7712, 23476, 15236, 3068, 15804, 10584, 15396, 10664, 3088, 4652, 27204, 7404, 15316, 4724, 7904, 1476, 15296, 4604, 7820, 16416, 7208, 21408, 6812, 8572, 14332, 7156, 16272, 7252, 4752, 16148, 3156, 12244, 11428, 13604, 12412, 17348, 16232, 3040, 12336, 8964, 12120, 5100, 2220, 14076, 7772, 15632, 3184, 15992, 6840, 7060, 22564, 11704, 13788, 3780, 15044, 15244, 10168, 11928, 5280, 12332, 7340, 16172, 3164, 11944, 344, 1444, 16164, 26880, 12116, 16072, 3556, 7044, 11908, 10256, 7068, 3876, 5480, 7072, 6476, 9672, 4668, 16092, 15884, 9536, 7708, 3420, 7132, 7480, 11232, 6636, 8320, 3076, 6896, 2404, 6264, 5452, 23564, 15604, 22524, 16408, 4728, 26316, 26840, 26592, 6524, 4220, 9148, 12188, 7448, 20416, 15916, 11372, 13732, 18728, 12092, 5604, 5392, 2344, 10124, 5360, 25664, 16680, 7516, 28048, 1060, 11844, 10232, 14684, 15964, 16772, 7068, 15360, 14472, 13376, 23296, 12244, 11988, 19100, 9392, 6264, 22844, 12324, 15252, 14000, 12036, 10496, 16236, 3804, 13360, 2616, 7160, 6968, 24436, 23348, 7412, 1400, 2432, 14468, 15472, 16560, 14512, 14360, 16904, 8768, 12616, 15340, 15888, 15236, 15488, 12392, 6384, 4128, 14456, 7292]
#     print(np.average(score_list))

#     best_list = [256, 128, 128, 64, 128, 128, 128, 128, 64, 256, 256, 128, 256, 128, 256, 64, 128, 128, 16, 128, 128, 64, 256, 64, 32, 256, 256, 128, 256, 128, 256, 128, 256, 256, 256, 256, 256, 256, 512, 256, 256, 128, 512, 256, 256, 256, 256, 256, 256, 256, 256, 512, 512, 256, 256, 512, 512, 256, 256, 512, 512, 512, 256, 256, 512, 256, 256, 512, 512, 512, 512, 512, 512, 512, 256, 512, 256, 512, 512, 512, 256, 256, 512, 1024, 256, 1024, 512, 1024, 512, 1024, 512, 512, 128, 512, 1024, 512, 256, 512, 512, 256, 512, 512, 1024, 512, 512, 512, 1024, 512, 512, 512, 256, 1024, 1024, 1024, 512, 512, 1024, 512, 128, 512, 1024, 1024, 512, 2048, 256, 1024, 512, 1024, 512, 1024, 1024, 1024, 256, 256, 1024, 512, 128, 1024, 1024, 1024, 64, 512, 256, 1024, 1024, 512, 1024, 256, 512, 64, 1024, 1024, 1024, 64, 1024, 512, 256, 512, 512, 1024, 512, 512, 512, 1024, 1024, 128, 256, 1024, 1024, 1024, 1024, 1024, 1024, 512, 512, 256, 1024, 1024, 1024, 256, 64, 1024, 1024, 2048, 1024, 512, 1024, 1024, 256, 512, 512, 1024, 512, 2048, 512, 2048, 512, 256, 256, 512, 1024, 512, 256, 1024, 1024, 512, 1024, 1024, 512, 512, 2048, 512, 512, 1024, 512, 512, 1024, 1024, 2048, 512, 512, 1024, 1024, 256, 1024, 512, 2048, 1024, 256, 1024, 2048, 512, 512, 1024, 512, 1024, 512, 1024, 1024, 1024, 512, 512, 512, 1024, 1024, 512, 512, 1024, 512, 256, 1024, 1024, 512, 512, 1024, 512, 2048, 512, 1024, 2048, 1024, 1024, 512, 512, 512, 256, 512, 2048, 512, 1024, 1024, 256, 512, 1024, 1024, 512, 1024, 1024, 1024, 512, 2048, 1024, 1024, 512, 1024, 1024, 1024, 512, 1024, 512, 1024, 512, 1024, 512, 256, 1024, 1024, 512, 512, 512, 1024, 512, 256, 512, 512, 512, 1024, 256, 1024, 512, 1024, 512, 512, 256, 512, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 128, 1024, 2048, 1024, 512, 2048, 1024, 1024, 1024, 1024, 512, 512, 256, 1024, 1024, 512, 512, 1024, 512, 1024, 1024, 512, 512, 512, 128, 512, 1024, 1024, 512, 512, 2048, 1024, 256, 1024, 512, 512, 1024, 256, 512, 2048, 512, 512, 1024, 512, 1024, 1024, 1024, 1024, 1024, 256, 1024, 256, 512, 1024, 256, 1024, 1024, 512, 1024, 1024, 256, 512, 1024, 1024, 1024, 512, 512, 1024, 1024, 512, 1024, 1024, 1024, 1024, 1024, 512, 1024, 1024, 512, 1024, 128, 1024, 1024, 1024, 1024, 256, 1024, 512, 1024, 512, 1024, 512, 2048, 1024, 512, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 256, 512, 512, 1024, 512, 1024, 512, 512, 1024, 1024, 1024, 1024, 256, 1024, 512, 512, 1024, 512, 256, 1024, 512, 2048, 512, 1024, 1024, 256, 512, 256, 512, 512, 1024, 1024, 512, 1024, 1024, 1024, 512, 512, 256, 256, 128, 512, 1024, 512, 512, 128, 1024, 1024, 512, 1024, 1024, 64, 256, 512, 1024, 1024, 1024, 512, 512, 1024, 512, 1024, 64, 256, 1024, 1024, 128, 1024, 512, 512, 32, 1024, 1024, 512, 512, 1024, 512, 512, 1024, 1024, 1024, 1024, 256, 1024, 1024, 256, 256, 1024, 1024, 1024, 1024, 1024, 1024, 512, 1024, 256, 1024, 1024, 1024, 512, 2048, 1024, 512, 512, 512, 512, 1024, 512, 2048, 1024, 2048, 512, 1024, 1024, 1024, 512, 512, 1024, 256, 1024, 1024, 1024, 1024, 1024, 512, 1024, 256, 1024, 1024, 1024, 512, 512, 128, 1024, 512, 1024, 512, 1024, 512, 1024, 1024, 512, 512, 1024, 1024, 1024, 2048, 1024, 1024, 512, 512, 1024, 256, 1024, 512, 512, 1024, 512, 1024, 512, 512, 512, 512, 1024, 512, 512, 256, 512, 512, 1024, 256, 1024, 1024, 2048, 512, 512, 1024, 1024, 1024, 512, 1024, 1024, 512, 256, 128, 1024, 1024, 512, 512, 256, 512, 2048, 512, 256, 512, 1024, 2048, 1024, 2048, 1024, 1024, 512, 1024, 512, 1024, 512, 1024, 1024, 2048, 1024, 1024, 1024, 256, 1024, 512, 1024, 256, 1024, 1024, 512, 1024, 512, 512, 128, 256, 512, 512, 1024, 1024, 2048, 512, 256, 1024, 512, 256, 512, 1024, 512, 512, 2048, 512, 128, 1024, 1024, 256, 2048, 1024, 1024, 1024, 512, 256, 1024, 1024, 2048, 2048, 64, 1024, 1024, 512, 512, 1024, 1024, 512, 256, 512, 256, 512, 1024, 1024, 512, 256, 1024, 1024, 1024, 1024, 512, 1024, 1024, 1024, 1024, 512, 1024, 1024, 256, 1024, 1024, 1024, 2048, 1024, 1024, 512, 512, 1024, 256, 1024, 256, 1024, 512, 1024, 256, 512, 2048, 512, 1024, 1024, 2048, 1024, 64, 512, 512, 1024, 1024, 1024, 1024, 1024, 256, 512, 1024, 256, 1024, 512, 512, 256, 1024, 1024, 1024, 1024, 128, 128, 256, 512, 2048, 512, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 512, 1024, 512, 512, 512, 1024, 1024, 1024, 1024, 512, 1024, 1024, 1024, 1024, 1024, 128, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 512, 256, 1024, 512, 256, 1024, 1024, 64, 512, 2048, 1024, 64, 512, 1024, 256, 2048, 1024, 128, 1024, 1024, 1024, 1024, 512, 128, 1024, 1024, 512, 1024, 1024, 512, 512, 1024, 1024, 1024, 512, 1024, 1024, 512, 512, 2048, 1024, 256, 1024, 1024, 1024, 1024, 256, 512, 2048, 512, 1024, 512, 512, 128, 1024, 256, 512, 1024, 512, 2048, 512, 512, 1024, 512, 1024, 512, 512, 1024, 256, 1024, 1024, 1024, 1024, 1024, 1024, 256, 1024, 512, 1024, 512, 256, 1024, 512, 1024, 256, 1024, 512, 512, 2048, 1024, 1024, 256, 1024, 1024, 1024, 1024, 512, 1024, 512, 1024, 256, 1024, 32, 128, 1024, 2048, 1024, 1024, 256, 512, 1024, 1024, 512, 256, 512, 512, 512, 1024, 512, 1024, 1024, 512, 512, 256, 512, 512, 1024, 512, 512, 256, 512, 256, 512, 512, 2048, 1024, 2048, 1024, 512, 2048, 2048, 2048, 512, 256, 512, 1024, 512, 1024, 1024, 1024, 1024, 1024, 1024, 512, 512, 256, 1024, 512, 2048, 1024, 512, 2048, 128, 1024, 1024, 1024, 1024, 1024, 512, 1024, 1024, 1024, 2048, 1024, 1024, 1024, 512, 512, 2048, 1024, 1024, 1024, 1024, 1024, 1024, 256, 1024, 256, 512, 512, 2048, 2048, 512, 128, 256, 1024, 1024, 1024, 1024, 1024, 1024, 512, 1024, 1024, 1024, 1024, 1024, 1024, 512, 256, 1024, 512]
#     print((np.count_nonzero(np.array(best_list) == 2048)/len(best_list)) * 100)

    # model = DQN()
    # pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    # print(pytorch_total_params)

    grid = np.zeros((4,4))
    grid[2,2] = 6
    # empty_cells = np.argwhere(grid == 0)
    # print(empty_cells)
    # empty_rightmost = empty_cells[empty_cells[:,1] == empty_cells[:,1].max(), :]
    # print(empty_rightmost)
    # idx, idy = empty_rightmost[empty_rightmost[:, 0] == empty_rightmost[:, 0].min(), :][0]
    # print(idx, idy)
    print(grid.max())